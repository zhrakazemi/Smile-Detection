{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# downloading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/zahra/.cache/kagglehub/datasets/talhasar/genki4k/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"talhasar/genki4k\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cropping face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'FaceAligner' from 'face_crop' (/home/zahra/Smile-Detection/face_crop.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mface_crop\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mface_crop\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FaceAligner\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'FaceAligner' from 'face_crop' (/home/zahra/Smile-Detection/face_crop.py)"
     ]
    }
   ],
   "source": [
    "from face_crop import FaceAligner\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'face_crop' has no attribute 'FaceAligner'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m face_aligner \u001b[38;5;241m=\u001b[39m face_crop\u001b[38;5;241m.\u001b[39mFaceAligner()\n\u001b[1;32m      3\u001b[0m dataset_path\u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;28mlist\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(path))[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      4\u001b[0m croped_path \u001b[38;5;241m=\u001b[39m dataset_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-cropped\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'face_crop' has no attribute 'FaceAligner'"
     ]
    }
   ],
   "source": [
    "face_aligner = FaceAligner()\n",
    "\n",
    "dataset_path= os.path.join(path, list(os.listdir(path))[0])\n",
    "cropped_path = dataset_path + '-cropped'\n",
    "\n",
    "for dir in os.listdir(dataset_path):\n",
    "    for root, _, files in os.walk(os.path.join(dataset_path, dir)):\n",
    "        os.makedirs(os.path.join(croped_path, dir), exist_ok=True)\n",
    "        for file in files:\n",
    "            face_image = face_aligner.align_face(os.path.join(root, file))\n",
    "            if face_image is not None:\n",
    "                cv2.imwrite(os.path.join(croped_path, dir, file), face_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatasetNotFoundError",
     "evalue": "Dataset my_dataset not found.\nAvailable datasets:\n\t- abstract_reasoning\n\t- accentdb\n\t- aeslc\n\t- aflw2k3d\n\t- ag_news_subset\n\t- ai2_arc\n\t- ai2_arc_with_ir\n\t- aloha_mobile\n\t- amazon_us_reviews\n\t- anli\n\t- answer_equivalence\n\t- arc\n\t- asqa\n\t- asset\n\t- assin2\n\t- asu_table_top_converted_externally_to_rlds\n\t- austin_buds_dataset_converted_externally_to_rlds\n\t- austin_sailor_dataset_converted_externally_to_rlds\n\t- austin_sirius_dataset_converted_externally_to_rlds\n\t- bair_robot_pushing_small\n\t- bc_z\n\t- bccd\n\t- beans\n\t- bee_dataset\n\t- beir\n\t- berkeley_autolab_ur5\n\t- berkeley_cable_routing\n\t- berkeley_fanuc_manipulation\n\t- berkeley_gnm_cory_hall\n\t- berkeley_gnm_recon\n\t- berkeley_gnm_sac_son\n\t- berkeley_mvp_converted_externally_to_rlds\n\t- berkeley_rpt_converted_externally_to_rlds\n\t- big_patent\n\t- bigearthnet\n\t- billsum\n\t- binarized_mnist\n\t- binary_alpha_digits\n\t- ble_wind_field\n\t- blimp\n\t- booksum\n\t- bool_q\n\t- bot_adversarial_dialogue\n\t- bridge\n\t- bridge_data_msr\n\t- bucc\n\t- c4\n\t- c4_wsrs\n\t- caltech101\n\t- caltech_birds2010\n\t- caltech_birds2011\n\t- cardiotox\n\t- cars196\n\t- cassava\n\t- cats_vs_dogs\n\t- celeb_a\n\t- celeb_a_hq\n\t- cfq\n\t- cherry_blossoms\n\t- chexpert\n\t- cifar10\n\t- cifar100\n\t- cifar100_n\n\t- cifar10_1\n\t- cifar10_corrupted\n\t- cifar10_h\n\t- cifar10_n\n\t- citrus_leaves\n\t- cityscapes\n\t- civil_comments\n\t- clevr\n\t- clic\n\t- clinc_oos\n\t- cmaterdb\n\t- cmu_franka_exploration_dataset_converted_externally_to_rlds\n\t- cmu_play_fusion\n\t- cmu_stretch\n\t- cnn_dailymail\n\t- coco\n\t- coco_captions\n\t- coil100\n\t- colorectal_histology\n\t- colorectal_histology_large\n\t- columbia_cairlab_pusht_real\n\t- common_voice\n\t- conll2002\n\t- conll2003\n\t- conq_hose_manipulation\n\t- controlled_noisy_web_labels\n\t- coqa\n\t- corr2cause\n\t- cos_e\n\t- cosmos_qa\n\t- covid19\n\t- covid19sum\n\t- crema_d\n\t- criteo\n\t- cs_restaurants\n\t- curated_breast_imaging_ddsm\n\t- cycle_gan\n\t- d4rl_adroit_door\n\t- d4rl_adroit_hammer\n\t- d4rl_adroit_pen\n\t- d4rl_adroit_relocate\n\t- d4rl_antmaze\n\t- d4rl_mujoco_ant\n\t- d4rl_mujoco_halfcheetah\n\t- d4rl_mujoco_hopper\n\t- d4rl_mujoco_walker2d\n\t- dart\n\t- databricks_dolly\n\t- davis\n\t- deep1b\n\t- deep_weeds\n\t- definite_pronoun_resolution\n\t- dementiabank\n\t- diabetic_retinopathy_detection\n\t- diamonds\n\t- dices\n\t- div2k\n\t- dlr_edan_shared_control_converted_externally_to_rlds\n\t- dlr_sara_grid_clamp_converted_externally_to_rlds\n\t- dlr_sara_pour_converted_externally_to_rlds\n\t- dmlab\n\t- dobbe\n\t- doc_nli\n\t- dolphin_number_word\n\t- domainnet\n\t- downsampled_imagenet\n\t- drop\n\t- dsprites\n\t- dtd\n\t- duke_ultrasound\n\t- e2e_cleaned\n\t- efron_morris75\n\t- emnist\n\t- eraser_multi_rc\n\t- esnli\n\t- eth_agent_affordances\n\t- eurosat\n\t- fashion_mnist\n\t- flic\n\t- flores\n\t- fmb\n\t- food101\n\t- forest_fires\n\t- fractal20220817_data\n\t- fuss\n\t- gap\n\t- geirhos_conflict_stimuli\n\t- gem\n\t- genomics_ood\n\t- german_credit_numeric\n\t- gigaword\n\t- glove100_angular\n\t- glue\n\t- goemotions\n\t- gov_report\n\t- gpt3\n\t- gref\n\t- groove\n\t- grounded_scan\n\t- gsm8k\n\t- gtzan\n\t- gtzan_music_speech\n\t- hellaswag\n\t- higgs\n\t- hillstrom\n\t- horses_or_humans\n\t- howell\n\t- i_naturalist2017\n\t- i_naturalist2018\n\t- i_naturalist2021\n\t- iamlab_cmu_pickup_insert_converted_externally_to_rlds\n\t- imagenet2012\n\t- imagenet2012_corrupted\n\t- imagenet2012_fewshot\n\t- imagenet2012_multilabel\n\t- imagenet2012_real\n\t- imagenet2012_subset\n\t- imagenet_a\n\t- imagenet_lt\n\t- imagenet_pi\n\t- imagenet_r\n\t- imagenet_resized\n\t- imagenet_sketch\n\t- imagenet_v2\n\t- imagenette\n\t- imagewang\n\t- imdb_reviews\n\t- imperialcollege_sawyer_wrist_cam\n\t- io_ai_tech\n\t- irc_disentanglement\n\t- iris\n\t- istella\n\t- jaco_play\n\t- kaist_nonprehensile_converted_externally_to_rlds\n\t- kddcup99\n\t- kitti\n\t- kmnist\n\t- kuka\n\t- laion400m\n\t- lambada\n\t- lfw\n\t- librispeech\n\t- librispeech_lm\n\t- libritts\n\t- ljspeech\n\t- lm1b\n\t- locomotion\n\t- lost_and_found\n\t- lsun\n\t- lvis\n\t- malaria\n\t- maniskill_dataset_converted_externally_to_rlds\n\t- math_dataset\n\t- math_qa\n\t- mctaco\n\t- media_sum\n\t- mimic_play\n\t- mlqa\n\t- mnist\n\t- mnist_corrupted\n\t- movie_lens\n\t- movie_rationales\n\t- movielens\n\t- moving_mnist\n\t- mrqa\n\t- mslr_web\n\t- mt_opt\n\t- mtnt\n\t- multi_news\n\t- multi_nli\n\t- multi_nli_mismatch\n\t- natural_instructions\n\t- natural_questions\n\t- natural_questions_open\n\t- newsroom\n\t- nsynth\n\t- nyu_depth_v2\n\t- nyu_door_opening_surprising_effectiveness\n\t- nyu_franka_play_dataset_converted_externally_to_rlds\n\t- nyu_rot_dataset_converted_externally_to_rlds\n\t- ogbg_molpcba\n\t- omniglot\n\t- open_images_challenge2019_detection\n\t- open_images_v4\n\t- openbookqa\n\t- opinion_abstracts\n\t- opinosis\n\t- opus\n\t- oxford_flowers102\n\t- oxford_iiit_pet\n\t- para_crawl\n\t- pass\n\t- patch_camelyon\n\t- paws_wiki\n\t- paws_x_wiki\n\t- penguins\n\t- pet_finder\n\t- pg19\n\t- piqa\n\t- places365_small\n\t- placesfull\n\t- plant_leaves\n\t- plant_village\n\t- plantae_k\n\t- plex_robosuite\n\t- protein_net\n\t- q_re_cc\n\t- qa4mre\n\t- qasc\n\t- qm9\n\t- quac\n\t- quality\n\t- quickdraw_bitmap\n\t- race\n\t- radon\n\t- real_toxicity_prompts\n\t- reddit\n\t- reddit_disentanglement\n\t- reddit_tifu\n\t- ref_coco\n\t- resisc45\n\t- rlu_atari\n\t- rlu_atari_checkpoints\n\t- rlu_atari_checkpoints_ordered\n\t- rlu_control_suite\n\t- rlu_dmlab_explore_object_rewards_few\n\t- rlu_dmlab_explore_object_rewards_many\n\t- rlu_dmlab_rooms_select_nonmatching_object\n\t- rlu_dmlab_rooms_watermaze\n\t- rlu_dmlab_seekavoid_arena01\n\t- rlu_locomotion\n\t- rlu_rwrl\n\t- robo_set\n\t- robomimic_mg\n\t- robomimic_mh\n\t- robomimic_ph\n\t- robonet\n\t- robosuite_panda_pick_place_can\n\t- roboturk\n\t- rock_paper_scissors\n\t- rock_you\n\t- s3o4d\n\t- salient_span_wikipedia\n\t- samsum\n\t- savee\n\t- scan\n\t- scene_parse150\n\t- schema_guided_dialogue\n\t- sci_tail\n\t- scicite\n\t- scientific_papers\n\t- scrolls\n\t- segment_anything\n\t- sentiment140\n\t- shapes3d\n\t- sift1m\n\t- simpte\n\t- siscore\n\t- smallnorb\n\t- smartwatch_gestures\n\t- snli\n\t- so2sat\n\t- speech_commands\n\t- spoc_robot\n\t- spoken_digit\n\t- squad\n\t- squad_question_generation\n\t- stanford_dogs\n\t- stanford_hydra_dataset_converted_externally_to_rlds\n\t- stanford_kuka_multimodal_dataset_converted_externally_to_rlds\n\t- stanford_mask_vit_converted_externally_to_rlds\n\t- stanford_online_products\n\t- stanford_robocook_converted_externally_to_rlds\n\t- star_cfq\n\t- starcraft_video\n\t- stl10\n\t- story_cloze\n\t- summscreen\n\t- sun397\n\t- super_glue\n\t- svhn_cropped\n\t- symmetric_solids\n\t- taco_play\n\t- tao\n\t- tatoeba\n\t- ted_hrlr_translate\n\t- ted_multi_translate\n\t- tedlium\n\t- tf_flowers\n\t- the300w_lp\n\t- tidybot\n\t- tiny_shakespeare\n\t- titanic\n\t- tokyo_u_lsmo_converted_externally_to_rlds\n\t- toto\n\t- trec\n\t- trivia_qa\n\t- tydi_qa\n\t- uc_merced\n\t- ucf101\n\t- ucsd_kitchen_dataset_converted_externally_to_rlds\n\t- ucsd_pick_and_place_dataset_converted_externally_to_rlds\n\t- uiuc_d3field\n\t- unified_qa\n\t- universal_dependencies\n\t- unnatural_instructions\n\t- usc_cloth_sim_converted_externally_to_rlds\n\t- user_libri_audio\n\t- user_libri_text\n\t- utaustin_mutex\n\t- utokyo_pr2_opening_fridge_converted_externally_to_rlds\n\t- utokyo_pr2_tabletop_manipulation_converted_externally_to_rlds\n\t- utokyo_saytap_converted_externally_to_rlds\n\t- utokyo_xarm_bimanual_converted_externally_to_rlds\n\t- utokyo_xarm_pick_and_place_converted_externally_to_rlds\n\t- vctk\n\t- vima_converted_externally_to_rlds\n\t- viola\n\t- visual_domain_decathlon\n\t- voc\n\t- voxceleb\n\t- voxforge\n\t- waymo_open_dataset\n\t- web_graph\n\t- web_nlg\n\t- web_questions\n\t- webvid\n\t- wider_face\n\t- wiki40b\n\t- wiki_auto\n\t- wiki_bio\n\t- wiki_dialog\n\t- wiki_table_questions\n\t- wiki_table_text\n\t- wikiann\n\t- wikihow\n\t- wikipedia\n\t- wikipedia_toxicity_subtypes\n\t- wine_quality\n\t- winogrande\n\t- wit\n\t- wit_kaggle\n\t- wmt13_translate\n\t- wmt14_translate\n\t- wmt15_translate\n\t- wmt16_translate\n\t- wmt17_translate\n\t- wmt18_translate\n\t- wmt19_translate\n\t- wmt_t2t_translate\n\t- wmt_translate\n\t- wordnet\n\t- wsc273\n\t- xnli\n\t- xquad\n\t- xsum\n\t- xtreme_pawsx\n\t- xtreme_pos\n\t- xtreme_s\n\t- xtreme_xnli\n\t- yahoo_ltrc\n\t- yelp_polarity_reviews\n\t- yes_no\n\t- youtube_vis\n\nCheck that:\n    - if dataset was added recently, it may only be available\n      in `tfds-nightly`\n    - the dataset name is spelled correctly\n    - dataset class defines all base class abstract methods\n    - the module defining the dataset class is imported\n\nDid you mean: my_dataset -> math_dataset ?\n\nThe builder directory /home/zahra/tensorflow_datasets/my_dataset doesn't contain any versions.\nNo builder could be found in the directory: /home/zahra/tensorflow_datasets for the builder: my_dataset.\nNo registered data_dirs were found in:\n\t- /home/zahra/tensorflow_datasets\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDatasetNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfds\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m ds \u001b[38;5;241m=\u001b[39m tfds\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmy_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain[:75\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ai-lab/lib/python3.12/site-packages/tensorflow_datasets/core/logging/__init__.py:169\u001b[0m, in \u001b[0;36m_FunctionDecorator.__call__\u001b[0;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_call()\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    171\u001b[0m   metadata\u001b[38;5;241m.\u001b[39mmark_error()\n",
      "File \u001b[0;32m~/miniconda3/envs/ai-lab/lib/python3.12/site-packages/tensorflow_datasets/core/load.py:641\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;129m@tfds_logging\u001b[39m\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[1;32m    511\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    526\u001b[0m ):\n\u001b[1;32m    527\u001b[0m   \u001b[38;5;66;03m# pylint: disable=line-too-long\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Loads the named dataset into a `tf.data.Dataset`.\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \n\u001b[1;32m    530\u001b[0m \u001b[38;5;124;03m  `tfds.load` is a convenience method that:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;124;03m      Split-specific information is available in `ds_info.splits`.\u001b[39;00m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m  \u001b[38;5;66;03m# fmt: skip\u001b[39;00m\n\u001b[0;32m--> 641\u001b[0m   dbuilder \u001b[38;5;241m=\u001b[39m _fetch_builder(\n\u001b[1;32m    642\u001b[0m       name,\n\u001b[1;32m    643\u001b[0m       data_dir,\n\u001b[1;32m    644\u001b[0m       builder_kwargs,\n\u001b[1;32m    645\u001b[0m       try_gcs,\n\u001b[1;32m    646\u001b[0m   )\n\u001b[1;32m    647\u001b[0m   _download_and_prepare_builder(dbuilder, download, download_and_prepare_kwargs)\n\u001b[1;32m    649\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m as_dataset_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ai-lab/lib/python3.12/site-packages/tensorflow_datasets/core/load.py:496\u001b[0m, in \u001b[0;36m_fetch_builder\u001b[0;34m(name, data_dir, builder_kwargs, try_gcs)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m builder_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    495\u001b[0m   builder_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m builder(name, data_dir\u001b[38;5;241m=\u001b[39mdata_dir, try_gcs\u001b[38;5;241m=\u001b[39mtry_gcs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbuilder_kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ai-lab/lib/python3.12/contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/miniconda3/envs/ai-lab/lib/python3.12/site-packages/tensorflow_datasets/core/logging/__init__.py:169\u001b[0m, in \u001b[0;36m_FunctionDecorator.__call__\u001b[0;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_call()\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m function(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    171\u001b[0m   metadata\u001b[38;5;241m.\u001b[39mmark_error()\n",
      "File \u001b[0;32m~/miniconda3/envs/ai-lab/lib/python3.12/site-packages/tensorflow_datasets/core/load.py:223\u001b[0m, in \u001b[0;36mbuilder\u001b[0;34m(name, try_gcs, **builder_kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbuilder_kwargs)  \u001b[38;5;66;03m# pytype: disable=not-instantiable\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m# If neither the code nor the files are found, raise DatasetNotFoundError\u001b[39;00m\n\u001b[0;32m--> 223\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m not_found_error\n",
      "File \u001b[0;32m~/miniconda3/envs/ai-lab/lib/python3.12/site-packages/tensorflow_datasets/core/load.py:200\u001b[0m, in \u001b[0;36mbuilder\u001b[0;34m(name, try_gcs, **builder_kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# First check whether we can find the corresponding dataset builder code\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m   \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m builder_cls(\u001b[38;5;28mstr\u001b[39m(name))\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m registered\u001b[38;5;241m.\u001b[39mDatasetNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m   \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Class not found\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ai-lab/lib/python3.12/contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/miniconda3/envs/ai-lab/lib/python3.12/site-packages/tensorflow_datasets/core/load.py:122\u001b[0m, in \u001b[0;36mbuilder_cls\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m registered\u001b[38;5;241m.\u001b[39mimported_builder_cls(\u001b[38;5;28mstr\u001b[39m(ds_name))\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m typing\u001b[38;5;241m.\u001b[39mcast(Type[dataset_builder\u001b[38;5;241m.\u001b[39mDatasetBuilder], \u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/ai-lab/lib/python3.12/site-packages/tensorflow_datasets/core/registered.py:372\u001b[0m, in \u001b[0;36mimported_builder_cls\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    370\u001b[0m   _import_legacy_builders()\n\u001b[1;32m    371\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _DATASET_REGISTRY:\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetNotFoundError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    374\u001b[0m builder_cls \u001b[38;5;241m=\u001b[39m _DATASET_REGISTRY[name]\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_builder_available(builder_cls):\n",
      "\u001b[0;31mDatasetNotFoundError\u001b[0m: Dataset my_dataset not found.\nAvailable datasets:\n\t- abstract_reasoning\n\t- accentdb\n\t- aeslc\n\t- aflw2k3d\n\t- ag_news_subset\n\t- ai2_arc\n\t- ai2_arc_with_ir\n\t- aloha_mobile\n\t- amazon_us_reviews\n\t- anli\n\t- answer_equivalence\n\t- arc\n\t- asqa\n\t- asset\n\t- assin2\n\t- asu_table_top_converted_externally_to_rlds\n\t- austin_buds_dataset_converted_externally_to_rlds\n\t- austin_sailor_dataset_converted_externally_to_rlds\n\t- austin_sirius_dataset_converted_externally_to_rlds\n\t- bair_robot_pushing_small\n\t- bc_z\n\t- bccd\n\t- beans\n\t- bee_dataset\n\t- beir\n\t- berkeley_autolab_ur5\n\t- berkeley_cable_routing\n\t- berkeley_fanuc_manipulation\n\t- berkeley_gnm_cory_hall\n\t- berkeley_gnm_recon\n\t- berkeley_gnm_sac_son\n\t- berkeley_mvp_converted_externally_to_rlds\n\t- berkeley_rpt_converted_externally_to_rlds\n\t- big_patent\n\t- bigearthnet\n\t- billsum\n\t- binarized_mnist\n\t- binary_alpha_digits\n\t- ble_wind_field\n\t- blimp\n\t- booksum\n\t- bool_q\n\t- bot_adversarial_dialogue\n\t- bridge\n\t- bridge_data_msr\n\t- bucc\n\t- c4\n\t- c4_wsrs\n\t- caltech101\n\t- caltech_birds2010\n\t- caltech_birds2011\n\t- cardiotox\n\t- cars196\n\t- cassava\n\t- cats_vs_dogs\n\t- celeb_a\n\t- celeb_a_hq\n\t- cfq\n\t- cherry_blossoms\n\t- chexpert\n\t- cifar10\n\t- cifar100\n\t- cifar100_n\n\t- cifar10_1\n\t- cifar10_corrupted\n\t- cifar10_h\n\t- cifar10_n\n\t- citrus_leaves\n\t- cityscapes\n\t- civil_comments\n\t- clevr\n\t- clic\n\t- clinc_oos\n\t- cmaterdb\n\t- cmu_franka_exploration_dataset_converted_externally_to_rlds\n\t- cmu_play_fusion\n\t- cmu_stretch\n\t- cnn_dailymail\n\t- coco\n\t- coco_captions\n\t- coil100\n\t- colorectal_histology\n\t- colorectal_histology_large\n\t- columbia_cairlab_pusht_real\n\t- common_voice\n\t- conll2002\n\t- conll2003\n\t- conq_hose_manipulation\n\t- controlled_noisy_web_labels\n\t- coqa\n\t- corr2cause\n\t- cos_e\n\t- cosmos_qa\n\t- covid19\n\t- covid19sum\n\t- crema_d\n\t- criteo\n\t- cs_restaurants\n\t- curated_breast_imaging_ddsm\n\t- cycle_gan\n\t- d4rl_adroit_door\n\t- d4rl_adroit_hammer\n\t- d4rl_adroit_pen\n\t- d4rl_adroit_relocate\n\t- d4rl_antmaze\n\t- d4rl_mujoco_ant\n\t- d4rl_mujoco_halfcheetah\n\t- d4rl_mujoco_hopper\n\t- d4rl_mujoco_walker2d\n\t- dart\n\t- databricks_dolly\n\t- davis\n\t- deep1b\n\t- deep_weeds\n\t- definite_pronoun_resolution\n\t- dementiabank\n\t- diabetic_retinopathy_detection\n\t- diamonds\n\t- dices\n\t- div2k\n\t- dlr_edan_shared_control_converted_externally_to_rlds\n\t- dlr_sara_grid_clamp_converted_externally_to_rlds\n\t- dlr_sara_pour_converted_externally_to_rlds\n\t- dmlab\n\t- dobbe\n\t- doc_nli\n\t- dolphin_number_word\n\t- domainnet\n\t- downsampled_imagenet\n\t- drop\n\t- dsprites\n\t- dtd\n\t- duke_ultrasound\n\t- e2e_cleaned\n\t- efron_morris75\n\t- emnist\n\t- eraser_multi_rc\n\t- esnli\n\t- eth_agent_affordances\n\t- eurosat\n\t- fashion_mnist\n\t- flic\n\t- flores\n\t- fmb\n\t- food101\n\t- forest_fires\n\t- fractal20220817_data\n\t- fuss\n\t- gap\n\t- geirhos_conflict_stimuli\n\t- gem\n\t- genomics_ood\n\t- german_credit_numeric\n\t- gigaword\n\t- glove100_angular\n\t- glue\n\t- goemotions\n\t- gov_report\n\t- gpt3\n\t- gref\n\t- groove\n\t- grounded_scan\n\t- gsm8k\n\t- gtzan\n\t- gtzan_music_speech\n\t- hellaswag\n\t- higgs\n\t- hillstrom\n\t- horses_or_humans\n\t- howell\n\t- i_naturalist2017\n\t- i_naturalist2018\n\t- i_naturalist2021\n\t- iamlab_cmu_pickup_insert_converted_externally_to_rlds\n\t- imagenet2012\n\t- imagenet2012_corrupted\n\t- imagenet2012_fewshot\n\t- imagenet2012_multilabel\n\t- imagenet2012_real\n\t- imagenet2012_subset\n\t- imagenet_a\n\t- imagenet_lt\n\t- imagenet_pi\n\t- imagenet_r\n\t- imagenet_resized\n\t- imagenet_sketch\n\t- imagenet_v2\n\t- imagenette\n\t- imagewang\n\t- imdb_reviews\n\t- imperialcollege_sawyer_wrist_cam\n\t- io_ai_tech\n\t- irc_disentanglement\n\t- iris\n\t- istella\n\t- jaco_play\n\t- kaist_nonprehensile_converted_externally_to_rlds\n\t- kddcup99\n\t- kitti\n\t- kmnist\n\t- kuka\n\t- laion400m\n\t- lambada\n\t- lfw\n\t- librispeech\n\t- librispeech_lm\n\t- libritts\n\t- ljspeech\n\t- lm1b\n\t- locomotion\n\t- lost_and_found\n\t- lsun\n\t- lvis\n\t- malaria\n\t- maniskill_dataset_converted_externally_to_rlds\n\t- math_dataset\n\t- math_qa\n\t- mctaco\n\t- media_sum\n\t- mimic_play\n\t- mlqa\n\t- mnist\n\t- mnist_corrupted\n\t- movie_lens\n\t- movie_rationales\n\t- movielens\n\t- moving_mnist\n\t- mrqa\n\t- mslr_web\n\t- mt_opt\n\t- mtnt\n\t- multi_news\n\t- multi_nli\n\t- multi_nli_mismatch\n\t- natural_instructions\n\t- natural_questions\n\t- natural_questions_open\n\t- newsroom\n\t- nsynth\n\t- nyu_depth_v2\n\t- nyu_door_opening_surprising_effectiveness\n\t- nyu_franka_play_dataset_converted_externally_to_rlds\n\t- nyu_rot_dataset_converted_externally_to_rlds\n\t- ogbg_molpcba\n\t- omniglot\n\t- open_images_challenge2019_detection\n\t- open_images_v4\n\t- openbookqa\n\t- opinion_abstracts\n\t- opinosis\n\t- opus\n\t- oxford_flowers102\n\t- oxford_iiit_pet\n\t- para_crawl\n\t- pass\n\t- patch_camelyon\n\t- paws_wiki\n\t- paws_x_wiki\n\t- penguins\n\t- pet_finder\n\t- pg19\n\t- piqa\n\t- places365_small\n\t- placesfull\n\t- plant_leaves\n\t- plant_village\n\t- plantae_k\n\t- plex_robosuite\n\t- protein_net\n\t- q_re_cc\n\t- qa4mre\n\t- qasc\n\t- qm9\n\t- quac\n\t- quality\n\t- quickdraw_bitmap\n\t- race\n\t- radon\n\t- real_toxicity_prompts\n\t- reddit\n\t- reddit_disentanglement\n\t- reddit_tifu\n\t- ref_coco\n\t- resisc45\n\t- rlu_atari\n\t- rlu_atari_checkpoints\n\t- rlu_atari_checkpoints_ordered\n\t- rlu_control_suite\n\t- rlu_dmlab_explore_object_rewards_few\n\t- rlu_dmlab_explore_object_rewards_many\n\t- rlu_dmlab_rooms_select_nonmatching_object\n\t- rlu_dmlab_rooms_watermaze\n\t- rlu_dmlab_seekavoid_arena01\n\t- rlu_locomotion\n\t- rlu_rwrl\n\t- robo_set\n\t- robomimic_mg\n\t- robomimic_mh\n\t- robomimic_ph\n\t- robonet\n\t- robosuite_panda_pick_place_can\n\t- roboturk\n\t- rock_paper_scissors\n\t- rock_you\n\t- s3o4d\n\t- salient_span_wikipedia\n\t- samsum\n\t- savee\n\t- scan\n\t- scene_parse150\n\t- schema_guided_dialogue\n\t- sci_tail\n\t- scicite\n\t- scientific_papers\n\t- scrolls\n\t- segment_anything\n\t- sentiment140\n\t- shapes3d\n\t- sift1m\n\t- simpte\n\t- siscore\n\t- smallnorb\n\t- smartwatch_gestures\n\t- snli\n\t- so2sat\n\t- speech_commands\n\t- spoc_robot\n\t- spoken_digit\n\t- squad\n\t- squad_question_generation\n\t- stanford_dogs\n\t- stanford_hydra_dataset_converted_externally_to_rlds\n\t- stanford_kuka_multimodal_dataset_converted_externally_to_rlds\n\t- stanford_mask_vit_converted_externally_to_rlds\n\t- stanford_online_products\n\t- stanford_robocook_converted_externally_to_rlds\n\t- star_cfq\n\t- starcraft_video\n\t- stl10\n\t- story_cloze\n\t- summscreen\n\t- sun397\n\t- super_glue\n\t- svhn_cropped\n\t- symmetric_solids\n\t- taco_play\n\t- tao\n\t- tatoeba\n\t- ted_hrlr_translate\n\t- ted_multi_translate\n\t- tedlium\n\t- tf_flowers\n\t- the300w_lp\n\t- tidybot\n\t- tiny_shakespeare\n\t- titanic\n\t- tokyo_u_lsmo_converted_externally_to_rlds\n\t- toto\n\t- trec\n\t- trivia_qa\n\t- tydi_qa\n\t- uc_merced\n\t- ucf101\n\t- ucsd_kitchen_dataset_converted_externally_to_rlds\n\t- ucsd_pick_and_place_dataset_converted_externally_to_rlds\n\t- uiuc_d3field\n\t- unified_qa\n\t- universal_dependencies\n\t- unnatural_instructions\n\t- usc_cloth_sim_converted_externally_to_rlds\n\t- user_libri_audio\n\t- user_libri_text\n\t- utaustin_mutex\n\t- utokyo_pr2_opening_fridge_converted_externally_to_rlds\n\t- utokyo_pr2_tabletop_manipulation_converted_externally_to_rlds\n\t- utokyo_saytap_converted_externally_to_rlds\n\t- utokyo_xarm_bimanual_converted_externally_to_rlds\n\t- utokyo_xarm_pick_and_place_converted_externally_to_rlds\n\t- vctk\n\t- vima_converted_externally_to_rlds\n\t- viola\n\t- visual_domain_decathlon\n\t- voc\n\t- voxceleb\n\t- voxforge\n\t- waymo_open_dataset\n\t- web_graph\n\t- web_nlg\n\t- web_questions\n\t- webvid\n\t- wider_face\n\t- wiki40b\n\t- wiki_auto\n\t- wiki_bio\n\t- wiki_dialog\n\t- wiki_table_questions\n\t- wiki_table_text\n\t- wikiann\n\t- wikihow\n\t- wikipedia\n\t- wikipedia_toxicity_subtypes\n\t- wine_quality\n\t- winogrande\n\t- wit\n\t- wit_kaggle\n\t- wmt13_translate\n\t- wmt14_translate\n\t- wmt15_translate\n\t- wmt16_translate\n\t- wmt17_translate\n\t- wmt18_translate\n\t- wmt19_translate\n\t- wmt_t2t_translate\n\t- wmt_translate\n\t- wordnet\n\t- wsc273\n\t- xnli\n\t- xquad\n\t- xsum\n\t- xtreme_pawsx\n\t- xtreme_pos\n\t- xtreme_s\n\t- xtreme_xnli\n\t- yahoo_ltrc\n\t- yelp_polarity_reviews\n\t- yes_no\n\t- youtube_vis\n\nCheck that:\n    - if dataset was added recently, it may only be available\n      in `tfds-nightly`\n    - the dataset name is spelled correctly\n    - dataset class defines all base class abstract methods\n    - the module defining the dataset class is imported\n\nDid you mean: my_dataset -> math_dataset ?\n\nThe builder directory /home/zahra/tensorflow_datasets/my_dataset doesn't contain any versions.\nNo builder could be found in the directory: /home/zahra/tensorflow_datasets for the builder: my_dataset.\nNo registered data_dirs were found in:\n\t- /home/zahra/tensorflow_datasets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the path to your dataset\n",
    "dataset_path = cropped_path\n",
    "\n",
    "# Parameters for splitting\n",
    "validation_split = 0.2  # 20% for validation\n",
    "batch_size = 32\n",
    "#img_size = (224, 224)  # Resize images to 224x224\n",
    "\n",
    "# Load training dataset\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    validation_split=validation_split,\n",
    "    subset=\"training\",\n",
    "    seed=123,  # Ensure reproducibility\n",
    "    #image_size=img_size,\n",
    "    batch_size=batch_size\n",
    "    #shuffle = true\n",
    ")\n",
    "\n",
    "# Load validation dataset\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_path,\n",
    "    validation_split=validation_split,\n",
    "    subset=\"validation\",\n",
    "    seed=123,  # Ensure reproducibility\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the first nine images and labels from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_dataset.class_names\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_dataset.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure the dataset for performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
